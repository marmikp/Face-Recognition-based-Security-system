{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do You Want Train Data? (Y/N) : \n",
      "n\n",
      "KNN accuracy = 0.9761904761904762, SVM accuracy = 0.9523809523809523\n",
      "KNN accuracy = 1.0, SVM accuracy = 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "import face1 as face1\n",
    "import sys\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from sklearn.manifold import TSNE\n",
    "import threading\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import cv2\n",
    "from handle import *\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "# Suppress LabelEncoder warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "import db_conn\n",
    "\n",
    "\n",
    "\n",
    "print(\"Do You Want Train Data? (Y/N) : \")\n",
    "ans_user = input()\n",
    "if ans_user==\"y\" or ans_user == \"Y\":\n",
    "    face1.create_embedded()\n",
    "    print(\"Data are Trained...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded1.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "dic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        dic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "embedded = np.load(\"tempFiles/embedding1.npy\")\n",
    "embedded2 = np.load(\"tempFiles/embedding2.npy\")\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded2.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "mic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        mic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "metadata = face1.metadata\n",
    "num = len(metadata)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "\n",
    "targets = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "# Numerical encoding of identities\n",
    "y = encoder.transform(targets)\n",
    "\n",
    "train_idx = np.arange(metadata.shape[0]) % 2 != 0\n",
    "test_idx = np.arange(metadata.shape[0]) % 2 == 0\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', gamma=1.0, C=1.0)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "acc_knn = accuracy_score(y_test, knn.predict(X_test))\n",
    "acc_svc = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(f'KNN accuracy = {acc_knn}, SVM accuracy = {acc_svc}')\n",
    "\n",
    "\n",
    "\n",
    "targets2 = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(targets2)\n",
    "\n",
    "y = encoder1.transform(targets2)\n",
    "\n",
    "train_idx = np.arange(metadata.shape[0]) % 2 != 0\n",
    "test_idx = np.arange(metadata.shape[0]) % 2 == 0\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded2[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded2[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "svc1 = svm.SVC(kernel='rbf', gamma=1, C=1.0, probability=True)\n",
    "\n",
    "knn1.fit(X_train, y_train)\n",
    "svc1.fit(X_train, y_train)\n",
    "\n",
    "acc_knn1 = accuracy_score(y_test, knn1.predict(X_test))\n",
    "acc_svc1 = accuracy_score(y_test, svc1.predict(X_test))\n",
    "print(f'KNN accuracy = {acc_knn1}, SVM accuracy = {acc_svc1}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_emd(img44):\n",
    "    im = face1.align_image(img44)\n",
    "    # scale RGB values to interval [0,1]\n",
    "    im = (im / 255.).astype(np.float32)\n",
    "    # obtain embedding vector for image\n",
    "    myemd = face1.nn4_small2_pretrained.predict(np.expand_dims(im, axis=0))[0]\n",
    "    \n",
    "    return myemd\n",
    "\n",
    "def testing_run(frame,per):\n",
    "    \n",
    "    try:\n",
    "        img= frame\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        \n",
    "\n",
    "        #print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "        for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "            top, right, bottom, left = face_location\n",
    "            # You can access the actual face itself like this:\n",
    "            face_image = img[top:bottom, left:right]\n",
    "            pil_image = Image.fromarray(face_image)\n",
    "            \n",
    "           \n",
    "            \n",
    "            example_idx = 20\n",
    "\n",
    "            example_idx = 20\n",
    "            example_image = np.asarray(face_image)\n",
    "\n",
    "            fd = face1.face_recognition.face_encodings(example_image)[0]\n",
    "            example_prediction1 = svc1.predict([fd])\n",
    "\n",
    "            example_identity1 = encoder1.inverse_transform(example_prediction1)[0]\n",
    "            thresh =0.25\n",
    "            thresh2 =0.40\n",
    "            \n",
    "            if face1.distance(mic[(example_identity1,0)],fd) < thresh and face1.distance(mic[(example_identity1,1)],fd) < thresh :\n",
    "                print(example_identity1)\n",
    "                data_maintain(example_identity1, per, face_image)\n",
    "               \n",
    "            elif face1.distance(mic[(example_identity1,0)],fd) < thresh2 and face1.distance(mic[(example_identity1,1)],fd) < thresh2 :\n",
    "            \tprint(example_identity1)\n",
    "            \tfor_asking(example_identity1, per, face_image)\n",
    "            else:\n",
    "            \tprint(\"unknown\")\n",
    "            \tdata_maintain(\"unknown\", per, face_image)\n",
    "        #plt.imshow(example_image)\n",
    "        #plt.title(f'Recognized as {example_identity}');\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "import time\n",
    "#cam1.release()\n",
    "#import pymysql\n",
    "\n",
    "# Open database connection\n",
    "#db = pymysql.connect(\"localhost\",\"root\",\"\",\"testing\" )\n",
    "\n",
    "# prepare a cursor object using cursor() method\n",
    "\n",
    "\n",
    "# execute SQL query using execute() method.\n",
    "\n",
    "# disconnect from server\n",
    "\n",
    "#detection algorithm\n",
    "\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = '/home/marmik/Desktop/Project/object_de/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "\n",
    "# ## Download Model\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())\n",
    "\n",
    "# ## Load a (frozen) Tensorflow model into memory.\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "# # Detection\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "\n",
    "class myThread1(threading.Thread):\n",
    "    def __init__(self, image, per):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.time = time\n",
    "        self.image = image\n",
    "        self.per = per\n",
    "    def run(self):\n",
    "      global graph1\n",
    "      with graph1.as_default():\n",
    "      \tif self.per != \"nothing\":\n",
    "      \t\tper = 1\n",
    "      \telse:\n",
    "      \t\tper = 0\n",
    "      \ttesting_run(self.image,per)\n",
    "\n",
    "\n",
    "\t\t\n",
    "         \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detection(img):\n",
    "\timage_np = img\n",
    "\timage_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\t#print(type(image_np_expanded))\n",
    "\timage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\tboxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\tscores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\tclasses = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\tnum_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\t(boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections],feed_dict={image_tensor: image_np_expanded})\n",
    "\timage_np,name1 = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "\treturn name1\n",
    "\n",
    "\n",
    "sess = tf.Session(graph=detection_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "list index out of range\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "list index out of range\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n",
      "jaimin\n",
      "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'jaimin''' at line 1\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cam1 = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\t_,img = cam1.read()\n",
    "\t\n",
    "\tgraph1 = tf.get_default_graph()\n",
    "\tper = detection(img)\n",
    "\tth1 = myThread1(img,per)\n",
    "\tth1.start()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
