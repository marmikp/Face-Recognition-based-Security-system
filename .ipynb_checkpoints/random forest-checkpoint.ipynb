{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy = 0.9761904761904762, SVM accuracy = 0.9523809523809523\n",
      "KNN accuracy = 1.0, SVM accuracy = 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import face1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded1.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "dic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        dic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "embedded = np.load(\"tempFiles/embedding1.npy\")\n",
    "embedded2 = np.load(\"tempFiles/embedding2.npy\")\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded2.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "mic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        mic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "metadata = face1.metadata\n",
    "num = len(metadata)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "\n",
    "targets = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "# Numerical encoding of identities\n",
    "y = encoder.transform(targets)\n",
    "\n",
    "train_idx = np.arange(metadata.shape[0]) % 2 != 0\n",
    "test_idx = np.arange(metadata.shape[0]) % 2 == 0\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "svc = svm.SVC(kernel='rbf', gamma=1.0, C=1.0)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "acc_knn = accuracy_score(y_test, knn.predict(X_test))\n",
    "acc_svc = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(f'KNN accuracy = {acc_knn}, SVM accuracy = {acc_svc}')\n",
    "\n",
    "\n",
    "\n",
    "targets2 = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(targets2)\n",
    "\n",
    "y = encoder1.transform(targets2)\n",
    "\n",
    "train_idx = np.arange(metadata.shape[0]) % 2 != 0\n",
    "test_idx = np.arange(metadata.shape[0]) % 2 == 0\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded2[train_idx]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded2[test_idx]\n",
    "\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=4, metric='euclidean')\n",
    "\n",
    "svc1 = svm.SVC(kernel='rbf', gamma=1, C=1.0, probability=True)\n",
    "\n",
    "knn1.fit(X_train, y_train)\n",
    "svc1.fit(X_train, y_train)\n",
    "\n",
    "acc_knn1 = accuracy_score(y_test, knn1.predict(X_test))\n",
    "acc_svc1 = accuracy_score(y_test, svc1.predict(X_test))\n",
    "print(f'KNN accuracy = {acc_knn1}, SVM accuracy = {acc_svc1}')\n",
    "\n",
    "\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "x_data = X_train.astype(np.float32)\n",
    "y_data = y_train.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "x_t=X_test.astype(np.float32)\n",
    "y_t = y_test.astype(np.float32)\n",
    "print(y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 30, 'max_nodes': 1000, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 11, 'max_fertile_nodes': 0, 'split_after_samples': 250, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 9, 'num_features': 128, 'bagged_num_features': 128, 'bagged_features': None, 'regression': False, 'num_outputs': 1, 'num_output_columns': 10, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0}\n",
      "Step 1, Loss: -1.000000, Acc: 0.119048\n",
      "Step 50, Loss: -11.400000, Acc: 1.000000\n",
      "Step 100, Loss: -22.266666, Acc: 1.000000\n",
      "Step 150, Loss: -29.066668, Acc: 1.000000\n",
      "Step 200, Loss: -32.200001, Acc: 1.000000\n",
      "Step 250, Loss: -34.799999, Acc: 1.000000\n",
      "Step 300, Loss: -35.533333, Acc: 1.000000\n",
      "Step 350, Loss: -36.000000, Acc: 1.000000\n",
      "Step 400, Loss: -36.000000, Acc: 1.000000\n",
      "Step 450, Loss: -36.000000, Acc: 1.000000\n",
      "Step 500, Loss: -36.000000, Acc: 1.000000\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "num_steps = 500 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "num_classes = 9 # The 10 digits\n",
    "num_features = 128 # Each image is 28x28 pixels\n",
    "num_trees = 30\n",
    "max_nodes = 1000\n",
    "tf.reset_default_graph() \n",
    "# Input and Target data\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "# For random forest, labels must be integers (the class id)\n",
    "Y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "# Random Forest Parameters\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()\n",
    "\n",
    "# Build the Random Forest\n",
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "# Get training graph and loss\n",
    "train_op = forest_graph.training_graph(X, Y)\n",
    "loss_op = forest_graph.training_loss(X, Y)\n",
    "\n",
    "# Measure the accuracy\n",
    "infer_op, _, _ = forest_graph.inference_graph(X)\n",
    "correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value) and forest resources\n",
    "init_vars = tf.group(tf.global_variables_initializer(),\n",
    "    resources.initialize_resources(resources.shared_resources()))\n",
    "\n",
    "# Start TensorFlow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init_vars)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps + 1):\n",
    "    # Prepare Data\n",
    " \n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={X: x_data, Y: y_data})\n",
    "    if i % 50 == 0 or i == 1:\n",
    "        acc = sess.run(accuracy_op, feed_dict={X: x_data, Y: y_data})\n",
    "        print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "\n",
    "\n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: x_t, Y: y_t}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
