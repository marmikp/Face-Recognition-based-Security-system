{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do You Want Train Data? (Y/N) : \n",
      "n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import struct\n",
    "import json\n",
    "import socket\n",
    "import h5py\n",
    "import face1 as face1\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from sklearn.manifold import TSNE\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import cv2\n",
    "from handle import *\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "# Suppress LabelEncoder warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "from db_conn import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "print(\"Do You Want Train Data? (Y/N) : \")\n",
    "ans_user = input()\n",
    "if ans_user==\"y\" or ans_user == \"Y\":\n",
    "    face1.create_embedded()\n",
    "    print(\"Data are Trained...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy = 1.0, SVM accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "svc1 = svm.SVC(kernel='rbf', gamma=1, C=1.0, probability=True)\n",
    "encoder1 =None\n",
    "mic = {}\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "def pre_load():\n",
    "    global knn1, svc1,encoder1,mic\n",
    "    metadata = face1.load_metadata('images')\n",
    "    num = len(metadata)\n",
    "    # embedded = np.empty(num)\n",
    "    embedded2 = np.empty(num)\n",
    "\n",
    "    # embedded = np.load(\"tempFiles/embedding1.npy\")\n",
    "    embedded2 = np.load(\"tempFiles/embedding2.npy\")\n",
    "\n",
    "\n",
    "\n",
    "    train_in =np.ones((metadata.shape[0]), dtype=bool)\n",
    "    test_in =np.ones((metadata.shape[0]), dtype=bool)\n",
    "    n1 =None\n",
    "    n2 =None\n",
    "    name=None\n",
    "    for i,m in enumerate(metadata):\n",
    "        if name==None:\n",
    "            name=m.name\n",
    "        if name!=m.name:\n",
    "            n1=None\n",
    "            #n2=None\n",
    "            name=None\n",
    "        if n1 ==None :\n",
    "            n1=1\n",
    "            train_in[i]=False\n",
    "            test_in[i]=True\n",
    "            continue\n",
    "    #     if n2 ==None :\n",
    "    #         n2=1\n",
    "    #         train_in[i]=False\n",
    "    #         continue\n",
    "        train_in[i]=True\n",
    "        test_in[i]=False\n",
    "\n",
    "\n",
    "\n",
    "    targets2 = np.array([m.name for m in metadata])\n",
    "\n",
    "    encoder1 = LabelEncoder()\n",
    "    encoder1.fit(targets2)\n",
    "\n",
    "    y = encoder1.transform(targets2)\n",
    "\n",
    "\n",
    "    # 50 train examples of 10 identities (5 examples each)\n",
    "    X_train = embedded2[train_in]\n",
    "    # 50 test examples of 10 identities (5 examples each)\n",
    "    X_test = embedded2[test_in]\n",
    "\n",
    "    y_train = y[train_in]\n",
    "    y_test = y[test_in]\n",
    "\n",
    "\n",
    "\n",
    "    knn1.fit(X_train, y_train)\n",
    "    svc1.fit(X_train, y_train)\n",
    "\n",
    "    acc_knn1 = accuracy_score(y_test, knn1.predict(X_test))\n",
    "    acc_svc1 = accuracy_score(y_test, svc1.predict(X_test))\n",
    "    print(f'KNN accuracy = {acc_knn1}, SVM accuracy = {acc_svc1}')\n",
    "    filename = 'tempFiles/embedded2.hdf5'\n",
    "    f = h5py.File(filename, 'r')\n",
    "    \n",
    "    for raw in f:\n",
    "        for j in f[raw]:\n",
    "            mic[str(raw),int(j)] = f[raw][j][:] \n",
    "            \n",
    "    f.close()\n",
    "pre_load()\n",
    "##############\n",
    "past_time = None\n",
    "def retrain():\n",
    "        now = datetime.datetime.now()\n",
    "        th =threading.current_thread()\n",
    "        global past_time\n",
    "        if past_time == None:\n",
    "                past_time = now\n",
    "        time_diff =int((now-past_time).total_seconds())/60\n",
    "        import platform\n",
    "        if platform.system() == 'Windows':\n",
    "            win =1\n",
    "        else:\n",
    "            win =0\n",
    "\n",
    "        if time_diff > 0.7:\n",
    "                past_time = now\n",
    "                print('New Face adding...')\n",
    "                th.main_c.execute(\"select * from add_person\")\n",
    "                data = main_c.fetchall()\n",
    "                th.main_c.execute(\"truncate table add_person\")\n",
    "                f = h5py.File('tempFiles/temp.hdf5','a')\n",
    "                g = h5py.File('tempFiles/embedded2.hdf5','a')\n",
    "                for d in data:\n",
    "                        iemd = f[d[1]].value\n",
    "                        del f[d[1]] \n",
    "                        gg = g.create_group(d[2])\n",
    "                        gg.create_dataset(str(0), data=iemd)\n",
    "                        if win !=1:\n",
    "                            os.system(\"mkdir images/\"+str(d[2]))\n",
    "                            os.system(\"mv temp_image/\"+str(d[1])+\" images/\"+str(d[2])+\"/1.jpg\")\n",
    "                        else:\n",
    "                            os.system(\"md images\\\\\"+str(d[2]))\n",
    "                            os.system(\"move temp_image\\\\\"+str(d[1])+\" images\\\\\"+str(d[2])+\"\\\\1.jpg\")\n",
    "                        no_img=1\n",
    "                        for key in f.keys():\n",
    "                            if face1.distance(f[key].value,iemd) < 0.30:\n",
    "                                gg.create_dataset(str(no_img), data=f[key].value)\n",
    "                                del f[key]\n",
    "                                th.main_c.execute('delete from notification where  img_name=%s',(key))\n",
    "                                \n",
    "                                if win !=1:\n",
    "                                    os.system(\"mv temp_image/\"+str(d[1])+\" images/\"+str(d[2])+\"/\"+str(no_img)+\".jpg\")\n",
    "                                else:\n",
    "                                    os.system(\"move temp_image\\\\\"+str(d[1])+\" images\\\\\"+str(d[2])+\"\\\\\"+str(no_img)+\".jpg\")\n",
    "                                no_img=no_img+1\n",
    "                        while no_img<4:\n",
    "                                if win !=1:\n",
    "                                    os.system(\"cp images/\"+str(d[2])+\"/\"+str(no_img-1)+\".jpg images/\"+str(d[2])+\"/\"+str(no_img)+\".jpg\")\n",
    "                                else:\n",
    "                                    os.system(\"copy images\\\\\"+str(d[2])+\"\\\\\"+str(no_img-1)+\".jpg images\\\\\"+str(d[2])+\"\\\\\"+str(no_img)+\".jpg\")\n",
    "                                no_img = no_img+1\n",
    "                        th.local_c.execute('insert into user_detail(name,no_img,last_update_date) values(%s,%s,%s)',(d[2],no_img,now.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "                # main_c.execute(\"select * from for_asking where flag = 1\")\n",
    "                # data1 = main_c.fetchall()\n",
    "                # main_c.execute(\"delete from for_asking where flag=1\")\n",
    "                # for d1 in data1:\n",
    "                #         local_c.execute(\"select no_img from user_detail where name = %s\",(d1[1]))\n",
    "                #         no_img = local_c.fetchone()\n",
    "                #         no = no_img[0] + 1\n",
    "                #         sf = len(os.listdir(os.pajoin(path, d1[1])))\n",
    "                #         s =int(sf)+1\n",
    "                #         local_c.execute(\"update user_detail set no_img = %s\",(no))\n",
    "                #         os.system(\"mv temp_image/\"+str(d1[2])+\" images/\"+str(d1[1])+\"/\"+s+\".jpg\")\n",
    "                f.close()\n",
    "                g.close()\n",
    "                print('### complete face adding ###')\n",
    "                if not len(data) == 0:\n",
    "                    pre_load()\n",
    "                #retrain model\n",
    "                #retrain model\n",
    "                \n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "# def return_emd(img44):\n",
    "#     im = face1.align_image(img44)\n",
    "#     # scale RGB values to interval [0,1]\n",
    "#     im = (im / 255.).astype(np.float32)\n",
    "#     # obtain embedding vector for image\n",
    "#     myemd = face1.nn4_small2_pretrained.predict(np.expand_dims(im, axis=0))[0]\n",
    "    \n",
    "#     return myemd\n",
    "\n",
    "\n",
    "###############\n",
    "\n",
    "def testing_run(frame):\n",
    "    \n",
    "    if 1:\n",
    "        img= frame.copy()\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        #print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "        if len(face_locations) ==0 :\n",
    "            print(\"noface\")\n",
    "            #data_maintain(\"noface\",img,np.array(np.random(1,128)))\n",
    "        else:    \n",
    "            for face_location in face_locations:\n",
    "\n",
    "                # Print the location of each face in this image\n",
    "                top, right, bottom, left = face_location\n",
    "\t\t\t\t# You can access the actual face itself like this:\n",
    "                face_image = img[top:bottom, left:right]\n",
    "                pil_image = Image.fromarray(face_image)\n",
    "                \n",
    "                \n",
    "            \n",
    "                example_image = np.asarray(face_image)\n",
    "\n",
    "                fd = face1.face_recognition.face_encodings(example_image)[0]\n",
    "                example_prediction1 = knn1.predict([fd])\n",
    "\n",
    "                example_identity1 = encoder1.inverse_transform(example_prediction1)[0]\n",
    "                thresh =0.30\n",
    "                thresh2 =0.40\n",
    "                \n",
    "                if face1.distance(mic[(example_identity1,0)],fd)<thresh and face1.distance(mic[(example_identity1,1)],fd) < thresh:\n",
    "                    print(example_identity1)\n",
    "                    data_maintain(example_identity1, face_image,fd)\n",
    "                   \n",
    "                # elif face1.distance(mic[(example_identity1,0)],fd) < thresh2 and face1.distance(mic[(example_identity1,1)],fd) < thresh2 :\n",
    "                #     print(example_identity1)\n",
    "                #     print(\"2\")\n",
    "                #     for_asking(example_identity1, face_image,fd)\n",
    "                else:\n",
    "                    print(\"unknown\")\n",
    "                    data_maintain(\"unknown\", face_image,fd)\n",
    "            \n",
    "   \n",
    "    # except Exception as e:\n",
    "    #      print(e)\n",
    "\n",
    "###################################\n",
    "\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())\n",
    "\n",
    "# ## Load a (frozen) Tensorflow model into memory.\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "global_lock = threading.Lock()\n",
    "fb = h5py.File('tempFiles/temp.hdf5','a')\n",
    "\n",
    "def write_to_file(img_name,emd):\n",
    "        while global_lock.locked():\n",
    "                continue\n",
    "\n",
    "        global_lock.acquire()\n",
    "        print('#### writing ###')\n",
    "        fb.create_dataset(img_name, data=emd)\n",
    "        global_lock.release()\n",
    "\n",
    "\n",
    "\n",
    "class myThread1(threading.Thread):\n",
    "    def __init__(self, image):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.time = time\n",
    "        self.image = image\n",
    "        self.per = None\n",
    "        self.db = PyMySQL.connect(\"localhost\",\"root\",\"\",\"main_db\" )\n",
    "        self.db1=PyMySQL.connect(\"localhost\",\"root\",\"\",\"local_db\" )\n",
    "        self.main_c = self.db.cursor()\n",
    "        self.local_c=self.db1.cursor()\n",
    "        self.img_n = None\n",
    "        self.temd =None\n",
    " \n",
    "        \n",
    "    def run(self):\n",
    "        self.per = detection(self.image.copy())\n",
    "        testing_run(self.image)\n",
    "        retrain()\n",
    "        self.db.commit()\n",
    "        self.db1.commit()\n",
    "        self.main_c.close()\n",
    "        self.local_c.close()\n",
    "        self.db.close()\n",
    "        self.db1.close()\n",
    "        if not self.img_n ==None:\n",
    "            write_to_file(self.img_n,self.temd)\n",
    "\n",
    "        \n",
    "         \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detection(img):\n",
    "    image_np = img\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    #print(type(image_np_expanded))\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections],feed_dict={image_tensor: image_np_expanded})\n",
    "    image_np,name1 = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    return name1\n",
    "\n",
    "\n",
    "in_upload = False\n",
    "clientsocket=None\n",
    "encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "past2 = datetime.datetime.now()\n",
    "def go_live(frame):\n",
    "    global in_upload,clientsocket,encode_param,past2\n",
    "    if in_upload:\n",
    "        now = datetime.datetime.now()\n",
    "        result, frame = cv2.imencode('.jpg', frame, encode_param)\n",
    "        data = pickle.dumps(frame, 0)\n",
    "        size = len(data)\n",
    "        clientsocket.sendall(struct.pack(\">L\", size) + data)\n",
    "        print(\"upload \")\n",
    "        if ((now-past2).total_seconds() / 60.0) > 0.30:\n",
    "            print(\"2min #########\")\n",
    "            main_c.execute(\"UPDATE variable set value='0' where name='live'\");\n",
    "            db.commit()\n",
    "            in_upload= False\n",
    "            clientsocket.close()\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        main_c.execute(\"select value from variable where name='live'\")\n",
    "        ll = main_c.fetchone()\n",
    "        db.commit()\n",
    "        if ll[0]=='1':\n",
    "            in_upload=True\n",
    "            past2 = datetime.datetime.now()\n",
    "            clientsocket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "            clientsocket.connect(('localhost',8089))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0c365fd0365e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mcam1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mdb1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'close'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaimin\n",
      "#### writing ###\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "cam1 = cv2.VideoCapture(0)\n",
    "sess = tf.Session(graph=detection_graph)\n",
    "mpast =datetime.datetime.now()\n",
    "for i in range(10):#while 10:\n",
    "    #try:\n",
    "        #clean_process()\n",
    "        _,img = cam1.read()\n",
    "        img2 =img.copy()\n",
    "        now = datetime.datetime.now()\n",
    "        if ((now-mpast).total_seconds()) > 0.30:\n",
    "            mpast=now\n",
    "            th1 = myThread1(img2)\n",
    "            th1.start()\n",
    "            \n",
    "        go_live(img)\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "cam1.release()\n",
    "db1.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
