{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import face1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded1.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "dic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        dic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "\n",
    "metadata = face1.metadata\n",
    "num = len(metadata)\n",
    "embedded = np.empty(num)\n",
    "embedded2 = np.empty(num)\n",
    "\n",
    "\n",
    "embedded = np.load(\"tempFiles/embedding1.npy\")\n",
    "embedded2 = np.load(\"tempFiles/embedding2.npy\")\n",
    "\n",
    "\n",
    "filename = 'tempFiles/embedded2.hdf5'\n",
    "f = h5py.File(filename, 'r')\n",
    "mic = {}\n",
    "for raw in f:\n",
    "    for j in f[raw]:\n",
    "        mic[str(raw),int(j)] = f[raw][j][:] \n",
    "        \n",
    "f.close()\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "distances = [] # squared L2 distance between pairs\n",
    "identical = [] # 1 if same identity, 0 otherwise\n",
    "metadata = face1.metadata\n",
    "num = len(metadata)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "\n",
    "train_in =np.ones((metadata.shape[0]), dtype=bool)\n",
    "test_in =np.ones((metadata.shape[0]), dtype=bool)\n",
    "n1 =None\n",
    "n2 =None\n",
    "name=None\n",
    "for i,m in enumerate(metadata):\n",
    "    if name==None:\n",
    "        name=m.name\n",
    "    if name!=m.name:\n",
    "        n1=None\n",
    "        #n2=None\n",
    "        name=None\n",
    "    if n1 ==None :\n",
    "        n1=1\n",
    "        train_in[i]=False\n",
    "        test_in[i]=True\n",
    "        continue\n",
    "    if n2 ==None :\n",
    "        n2=1\n",
    "        train_in[i]=False\n",
    "        continue\n",
    "    train_in[i]=True\n",
    "    test_in[i]=False\n",
    "\n",
    "\n",
    "\n",
    "targets2 = np.array([m.name for m in metadata])\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(targets2)\n",
    "\n",
    "y = encoder1.transform(targets2)\n",
    "\n",
    "\n",
    "# 50 train examples of 10 identities (5 examples each)\n",
    "X_train = embedded2[train_in]\n",
    "# 50 test examples of 10 identities (5 examples each)\n",
    "X_test = embedded2[test_in]\n",
    "\n",
    "y_train = y[train_in]\n",
    "y_test = y[test_in]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 70, 'max_nodes': 2000, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 11, 'max_fertile_nodes': 0, 'split_after_samples': 250, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 9, 'num_features': 128, 'bagged_num_features': 128, 'bagged_features': None, 'regression': False, 'num_outputs': 1, 'num_output_columns': 10, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0}\n",
      "Step 1, Loss: -1.000000, Acc: 0.121622\n",
      "Step 50, Loss: -19.828571, Acc: 1.000000\n",
      "Step 100, Loss: -34.599998, Acc: 1.000000\n",
      "Step 150, Loss: -41.371429, Acc: 1.000000\n",
      "Step 200, Loss: -45.799999, Acc: 1.000000\n",
      "Step 250, Loss: -48.742859, Acc: 1.000000\n",
      "Step 300, Loss: -50.799999, Acc: 1.000000\n",
      "Step 350, Loss: -51.057144, Acc: 1.000000\n",
      "Step 400, Loss: -51.085712, Acc: 1.000000\n",
      "Step 450, Loss: -51.085712, Acc: 1.000000\n",
      "Step 500, Loss: -51.085712, Acc: 1.000000\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
